import asyncio
import json
import time
import os

# psutilì´ ì—†ëŠ” ê²½ìš°ë¥¼ ìœ„í•œ fallback
try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    print("âš ï¸ psutilì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì œí•œë¨")
    HAS_PSUTIL = False
from app.routes.simulation import reset_simulation_state
from app.simulation_engine import step_simulation, run_simulation
from app.models import SimulationSetup, ProcessBlockConfig, ConnectionConfig
from app.entity import get_active_entity_states

class PerformanceProfiler:
    """ì„±ëŠ¥ ë¶„ì„ì„ ìœ„í•œ ìƒì„¸ í”„ë¡œíŒŒì¼ëŸ¬"""
    
    def __init__(self):
        self.step_times = []
        self.api_times = []
        self.memory_usage = []
        self.cpu_usage = []
        
    def record_step(self, step_time, memory_mb=0, cpu_percent=0):
        self.step_times.append(step_time)
        if memory_mb > 0:
            self.memory_usage.append(memory_mb)
        if cpu_percent > 0:
            self.cpu_usage.append(cpu_percent)
    
    def record_api_call(self, api_time):
        self.api_times.append(api_time)
    
    def get_summary(self):
        if not self.step_times:
            return {}
            
        return {
            "step_performance": {
                "total_steps": len(self.step_times),
                "avg_step_time_ms": sum(self.step_times) * 1000 / len(self.step_times),
                "min_step_time_ms": min(self.step_times) * 1000,
                "max_step_time_ms": max(self.step_times) * 1000,
                "steps_per_second": len(self.step_times) / sum(self.step_times) if sum(self.step_times) > 0 else 0
            },
            "api_performance": {
                "total_calls": len(self.api_times),
                "avg_api_time_ms": sum(self.api_times) * 1000 / len(self.api_times) if self.api_times else 0,
                "total_api_time_ms": sum(self.api_times) * 1000
            },
            "system_resources": {
                "avg_memory_mb": sum(self.memory_usage) / len(self.memory_usage) if self.memory_usage else 0,
                "max_memory_mb": max(self.memory_usage) if self.memory_usage else 0,
                "avg_cpu_percent": sum(self.cpu_usage) / len(self.cpu_usage) if self.cpu_usage else 0,
                "max_cpu_percent": max(self.cpu_usage) if self.cpu_usage else 0
            }
        }

async def test_current_vs_old_performance():
    """í˜„ì¬ ë¦¬íŒ©í† ë§ëœ ì½”ë“œì™€ ì´ì „ ì„±ëŠ¥ ë¹„êµ"""
    
    print("ğŸ”¥ DETAILED PERFORMANCE ANALYSIS: Current vs main_old.py")
    print("=" * 80)
    
    # ì‹œìŠ¤í…œ ì •ë³´
    if HAS_PSUTIL:
        process = psutil.Process(os.getpid())
        print(f"ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´:")
        print(f"  Python PID: {os.getpid()}")
        print(f"  CPU ì½”ì–´: {psutil.cpu_count()}")
        print(f"  ë©”ëª¨ë¦¬: {psutil.virtual_memory().total / (1024**3):.1f}GB")
    else:
        process = None
        print(f"ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´:")
        print(f"  Python PID: {os.getpid()}")
    print()
    
    # base.json ë¡œë“œ
    with open("../base.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    
    # ID íƒ€ì… ë³€í™˜
    blocks_data = []
    for block in data["blocks"]:
        block_copy = block.copy()
        block_copy["id"] = str(block_copy["id"])
        blocks_data.append(block_copy)
    
    connections_data = []
    for conn in data["connections"]:
        conn_copy = conn.copy()
        conn_copy["from_block_id"] = str(conn_copy["from_block_id"])
        conn_copy["to_block_id"] = str(conn_copy["to_block_id"])
        connections_data.append(conn_copy)
    
    setup = SimulationSetup(
        blocks=[ProcessBlockConfig(**block) for block in blocks_data],
        connections=[ConnectionConfig(**conn) for conn in connections_data],
        initial_entities=1,
        initial_signals={"ê³µì •1 load enable": True}
    )
    
    # 1. í˜„ì¬ ë¦¬íŒ©í† ë§ëœ ì½”ë“œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ 1: í˜„ì¬ ë¦¬íŒ©í† ë§ëœ ì½”ë“œ (step_simulation)")
    print("-" * 60)
    
    profiler = PerformanceProfiler()
    
    # ì´ˆê¸°í™” ì‹œê°„ ì¸¡ì •
    init_start = time.time()
    reset_simulation_state()
    init_time = time.time() - init_start
    print(f"ğŸ”„ ì´ˆê¸°í™” ì‹œê°„: {init_time*1000:.2f}ms")
    
    # ìŠ¤í…ë³„ ìƒì„¸ ì„±ëŠ¥ ì¸¡ì •
    total_steps = 30
    for i in range(1, total_steps + 1):
        # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì¸¡ì •
        if HAS_PSUTIL and process:
            memory_mb = process.memory_info().rss / (1024 * 1024)
            cpu_percent = process.cpu_percent()
        else:
            memory_mb = 0
            cpu_percent = 0
        
        # ìŠ¤í… ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
        step_start = time.time()
        try:
            result = await step_simulation(setup if i == 1 else None)
            step_time = time.time() - step_start
            
            profiler.record_step(step_time, memory_mb, cpu_percent)
            
            # ì²« 10ìŠ¤í…ê³¼ ë§ˆì§€ë§‰ ëª‡ ìŠ¤í… ìƒì„¸ ë¡œê·¸
            if i <= 5 or i % 10 == 0 or i >= total_steps - 2:
                print(f"  Step {i:2d}: {step_time*1000:6.2f}ms | Time: {result.time:5.1f}s | Mem: {memory_mb:6.1f}MB | CPU: {cpu_percent:5.1f}%")
            
            # 2ê°œ ì œí’ˆ ì²˜ë¦¬ë˜ë©´ ì¤‘ë‹¨
            if result.entities_processed_total >= 2:
                print(f"  ğŸ¯ 2ê°œ ì œí’ˆ ì™„ë£Œ: {i}ë²ˆì§¸ ìŠ¤í…ì—ì„œ ì¤‘ë‹¨")
                break
                
        except Exception as e:
            print(f"  âŒ Step {i} ì˜¤ë¥˜: {e}")
            break
    
    current_summary = profiler.get_summary()
    
    print(f"\nğŸ“ˆ í˜„ì¬ ì½”ë“œ ì„±ëŠ¥ ìš”ì•½:")
    print(f"  í‰ê·  ìŠ¤í… ì‹œê°„: {current_summary['step_performance']['avg_step_time_ms']:.2f}ms")
    print(f"  ìµœì†Œ/ìµœëŒ€ ìŠ¤í… ì‹œê°„: {current_summary['step_performance']['min_step_time_ms']:.2f}ms / {current_summary['step_performance']['max_step_time_ms']:.2f}ms")
    print(f"  ìŠ¤í…/ì´ˆ: {current_summary['step_performance']['steps_per_second']:.0f}")
    print(f"  í‰ê·  ë©”ëª¨ë¦¬: {current_summary['system_resources']['avg_memory_mb']:.1f}MB")
    print(f"  í‰ê·  CPU: {current_summary['system_resources']['avg_cpu_percent']:.1f}%")
    
    # 2. ì „ì²´ ì‹¤í–‰ ì„±ëŠ¥ ë¹„êµ (run_simulation)
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ 2: ì „ì²´ ì‹¤í–‰ ì„±ëŠ¥ (run_simulation)")
    print("-" * 60)
    
    reset_simulation_state()
    
    setup_run = SimulationSetup(
        blocks=[ProcessBlockConfig(**block) for block in blocks_data],
        connections=[ConnectionConfig(**conn) for conn in connections_data],
        initial_entities=1,
        initial_signals={"ê³µì •1 load enable": True},
        stop_entities_processed=3,  # 3ê°œ ì œí’ˆê¹Œì§€
        stop_time=50  # 50ì´ˆ ì œí•œ
    )
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • ì‹œì‘
    if HAS_PSUTIL and process:
        memory_before = process.memory_info().rss / (1024 * 1024)
    else:
        memory_before = 0
    
    start_time = time.time()
    result = await run_simulation(setup_run)
    end_time = time.time()
    
    if HAS_PSUTIL and process:
        memory_after = process.memory_info().rss / (1024 * 1024)
        memory_diff = memory_after - memory_before
    else:
        memory_diff = 0
    
    run_time = end_time - start_time
    entities_per_sec = result.total_entities_processed / run_time if run_time > 0 else 0
    
    print(f"  ì‹¤í–‰ ì‹œê°„: {run_time*1000:.2f}ms")
    print(f"  ì²˜ë¦¬ëœ ì œí’ˆ: {result.total_entities_processed}ê°œ")
    print(f"  ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„: {result.final_time:.1f}ì´ˆ")
    print(f"  ì œí’ˆ/ì´ˆ (ì‹¤ì œ): {entities_per_sec:.2f}")
    print(f"  ë©”ëª¨ë¦¬ ì¦ê°€: {memory_diff:.1f}MB")
    print(f"  ì‹¤ì‹œê°„ ë¹„ìœ¨: {result.final_time/run_time:.0f}x")
    
    # 3. ì„±ëŠ¥ ë³‘ëª© ë¶„ì„
    print(f"\nğŸ” ì„±ëŠ¥ ë³‘ëª© ë¶„ì„")
    print("-" * 40)
    
    # ëŠë¦° ìŠ¤í…ë“¤ ë¶„ì„
    slow_steps = [(i+1, t*1000) for i, t in enumerate(profiler.step_times) if t > current_summary['step_performance']['avg_step_time_ms']/1000 * 2]
    if slow_steps:
        print(f"  ğŸŒ í‰ê· ë³´ë‹¤ 2ë°° ì´ìƒ ëŠë¦° ìŠ¤í…ë“¤:")
        for step_num, step_time in slow_steps[:5]:
            print(f"    Step {step_num}: {step_time:.2f}ms")
    
    # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì²´í¬
    if len(profiler.memory_usage) > 5:
        memory_trend = profiler.memory_usage[-1] - profiler.memory_usage[0]
        if memory_trend > 5:  # 5MB ì´ìƒ ì¦ê°€
            print(f"  âš ï¸ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì˜ì‹¬: {memory_trend:.1f}MB ì¦ê°€")
        else:
            print(f"  âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•ˆì •: {memory_trend:.1f}MB ë³€í™”")
    
    # CPU ì‚¬ìš©ë¥  ë¶„ì„
    if current_summary['system_resources']['max_cpu_percent'] > 80:
        print(f"  ğŸ”¥ ë†’ì€ CPU ì‚¬ìš©ë¥ : ìµœëŒ€ {current_summary['system_resources']['max_cpu_percent']:.1f}%")
    else:
        print(f"  âœ… CPU ì‚¬ìš©ë¥  ì–‘í˜¸: í‰ê·  {current_summary['system_resources']['avg_cpu_percent']:.1f}%")
    
    return current_summary

async def test_api_overhead():
    """API í˜¸ì¶œ ì˜¤ë²„í—¤ë“œ ì¸¡ì •"""
    
    print(f"\nğŸ“¡ API í˜¸ì¶œ ì˜¤ë²„í—¤ë“œ ë¶„ì„")
    print("-" * 50)
    
    # FastAPI ë¼ìš°íŠ¸ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ HTTP í˜¸ì¶œ ì—†ì´ í•¨ìˆ˜ ì§ì ‘ í˜¸ì¶œ)
    # ëª¨ë¸ import ì œê±°í•˜ê³  ì§ì ‘ API í•¨ìˆ˜ í˜¸ì¶œ ì‚¬ìš©
    
    # base.json ë¡œë“œ
    with open("../base.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    
    # ì´ˆê¸°í™”
    reset_simulation_state()
    
    # API í˜¸ì¶œ ì‹œê°„ ì¸¡ì • (ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ)
    api_times = []
    
    # ì„¤ì • ë°ì´í„° ì¤€ë¹„
    blocks_data = []
    for block in data["blocks"]:
        block_copy = block.copy()
        block_copy["id"] = str(block_copy["id"])
        blocks_data.append(block_copy)
    
    connections_data = []
    for conn in data["connections"]:
        conn_copy = conn.copy()
        conn_copy["from_block_id"] = str(conn_copy["from_block_id"])
        conn_copy["to_block_id"] = str(conn_copy["to_block_id"])
        connections_data.append(conn_copy)
    
    setup = SimulationSetup(
        blocks=[ProcessBlockConfig(**block) for block in blocks_data],
        connections=[ConnectionConfig(**conn) for conn in connections_data],
        initial_entities=1,
        initial_signals={"ê³µì •1 load enable": True}
    )
    
    for i in range(1, 11):
        api_start = time.time()
        
        try:
            if i == 1:
                result = await step_simulation(setup)
            else:
                result = await step_simulation()
            api_time = time.time() - api_start
            api_times.append(api_time)
            
            print(f"  API Call {i}: {api_time*1000:.2f}ms")
            
        except Exception as e:
            print(f"  âŒ API Call {i} ì˜¤ë¥˜: {e}")
            break
    
    if api_times:
        avg_api_time = sum(api_times) / len(api_times)
        print(f"\n  ğŸ“Š API ì„±ëŠ¥ ìš”ì•½:")
        print(f"    í‰ê·  API í˜¸ì¶œ ì‹œê°„: {avg_api_time*1000:.2f}ms")
        print(f"    ìµœì†Œ/ìµœëŒ€: {min(api_times)*1000:.2f}ms / {max(api_times)*1000:.2f}ms")
        print(f"    API í˜¸ì¶œ/ì´ˆ: {1/avg_api_time:.0f}")

async def test_frontend_simulation():
    """í”„ë¡ íŠ¸ì—”ë“œ ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    print(f"\nğŸ¨ í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸")
    print("-" * 50)
    
    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” íŒ¨í„´ ì‹œë®¬ë ˆì´ì…˜
    frontend_times = []
    
    for i in range(1, 21):
        start_time = time.time()
        
        # 1. ìŠ¤í… ì‹¤í–‰
        result = await step_simulation()
        
        # 2. ì—”í‹°í‹° ìƒíƒœ ì¡°íšŒ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ UI ì—…ë°ì´íŠ¸ìš©)
        entities = get_active_entity_states()
        
        # 3. ì¶”ê°€ ë°ì´í„° ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        entity_data = []
        for entity in entities:
            if hasattr(entity, 'id') and hasattr(entity, 'current_block_id'):
                entity_data.append({
                    "id": entity.id,
                    "block_id": entity.current_block_id,
                    "block_name": getattr(entity, 'current_block_name', 'Unknown')
                })
        
        end_time = time.time()
        frontend_time = end_time - start_time
        frontend_times.append(frontend_time)
        
        if i <= 5 or i % 5 == 0:
            print(f"  Frontend Cycle {i}: {frontend_time*1000:.2f}ms | Entities: {len(entity_data)}")
    
    if frontend_times:
        avg_frontend_time = sum(frontend_times) / len(frontend_times)
        print(f"\n  ğŸ“Š í”„ë¡ íŠ¸ì—”ë“œ ì‹œë®¬ë ˆì´ì…˜ ì„±ëŠ¥:")
        print(f"    í‰ê·  ì‚¬ì´í´ ì‹œê°„: {avg_frontend_time*1000:.2f}ms")
        print(f"    ì‚¬ì´í´/ì´ˆ: {1/avg_frontend_time:.0f}")

async def main():
    """ë©”ì¸ ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰"""
    
    print("ğŸš€ COMPREHENSIVE PERFORMANCE ANALYSIS")
    print("=" * 100)
    print("ğŸ¯ ëª©í‘œ: ë¦¬íŒ©í† ë§ ì „ main_old.py ëŒ€ë¹„ ì„±ëŠ¥ ì €í•˜ ì›ì¸ íŒŒì•…")
    print()
    
    # í˜„ì¬ ì„±ëŠ¥ ì¸¡ì •
    current_perf = await test_current_vs_old_performance()
    
    # API ì˜¤ë²„í—¤ë“œ ì¸¡ì •
    await test_api_overhead()
    
    # í”„ë¡ íŠ¸ì—”ë“œ ì‹œë®¬ë ˆì´ì…˜
    await test_frontend_simulation()
    
    # ìµœì¢… ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­
    print(f"\nğŸ ìµœì¢… ë¶„ì„ ê²°ê³¼")
    print("=" * 80)
    
    avg_step_ms = current_perf['step_performance']['avg_step_time_ms']
    steps_per_sec = current_perf['step_performance']['steps_per_second']
    
    print(f"ğŸ“Š í˜„ì¬ ì„±ëŠ¥:")
    print(f"  ìŠ¤í…/ì´ˆ: {steps_per_sec:.0f}")
    print(f"  í‰ê·  ìŠ¤í… ì‹œê°„: {avg_step_ms:.2f}ms")
    
    print(f"\nğŸ” ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥í•œ ì›ì¸ë“¤:")
    
    if avg_step_ms > 1.0:
        print(f"  âŒ ìŠ¤í… ì‹¤í–‰ ì‹œê°„ì´ 1ms ì´ìƒ - ë°±ì—”ë“œ ìµœì í™” í•„ìš”")
    else:
        print(f"  âœ… ìŠ¤í… ì‹¤í–‰ ì‹œê°„ ì–‘í˜¸ ({avg_step_ms:.2f}ms)")
    
    if current_perf['system_resources']['avg_memory_mb'] > 100:
        print(f"  âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ - ë©”ëª¨ë¦¬ ìµœì í™” ê²€í†  í•„ìš”")
    else:
        print(f"  âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì–‘í˜¸")
    
    print(f"\nğŸ’¡ ê¶Œì¥ ê°œì„  ì‚¬í•­:")
    print(f"  1. ë°±ì—”ë“œ ìµœì í™”: PERFORMANCE_MODE í™œì„±í™” ìƒíƒœ í™•ì¸")
    print(f"  2. í”„ë¡ íŠ¸ì—”ë“œ ìµœì í™”: ë¶ˆí•„ìš”í•œ API í˜¸ì¶œ ìµœì†Œí™”")
    print(f"  3. ìºì‹± ì‹œìŠ¤í…œ: ì—”í‹°í‹° ìƒíƒœ ìºì‹± ê°•í™”")
    print(f"  4. ë©”ëª¨ë¦¬ ê´€ë¦¬: ì—”í‹°í‹° í’€ë§ ìµœì í™”")
    
    if steps_per_sec < 5000:
        print(f"\nğŸš¨ ì„±ëŠ¥ ê²½ê³ : main_old.py ëŒ€ë¹„ ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ëœ ìƒíƒœ")
        print(f"   ê¶Œì¥: ëª¨ë“ˆ êµ¬ì¡° ë‹¨ìˆœí™” ë˜ëŠ” main_old.py íŒ¨í„´ ë³µì› ê²€í† ")
    elif steps_per_sec < 15000:
        print(f"\nâš ï¸ ì„±ëŠ¥ ì£¼ì˜: ì¶”ê°€ ìµœì í™”ê°€ í•„ìš”í•œ ìƒíƒœ")
    else:
        print(f"\nâœ… ì„±ëŠ¥ ì–‘í˜¸: í˜„ì¬ ìµœì í™” ìƒíƒœê°€ ìš°ìˆ˜í•¨")

if __name__ == "__main__":
    asyncio.run(main())